# Stack ELK avec Docker (Elasticsearch + Logstash + Kibana)

ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

---

## ğŸ“‹ Introduction

Cette fiche vous guide dans la crÃ©ation d'une **stack ELK complÃ¨te** avec Docker. ELK est l'acronyme de **Elasticsearch + Logstash + Kibana**, une solution puissante et populaire pour la collecte, le stockage, l'analyse et la visualisation de donnÃ©es de logs en temps rÃ©el.

**Ce que vous allez apprendre :**
- Comprendre l'architecture et le rÃ´le de chaque composant ELK
- DÃ©ployer Elasticsearch, Logstash et Kibana avec Docker Compose
- Configurer la collecte et l'indexation de logs
- CrÃ©er des visualisations et des tableaux de bord dans Kibana
- GÃ©rer et interroger vos donnÃ©es avec Elasticsearch
- Suivre les bonnes pratiques de configuration

**DurÃ©e estimÃ©e :** 40-50 minutes

---

## ğŸ¯ Qu'est-ce que la Stack ELK ?

### DÃ©finition

La **stack ELK** est une suite d'outils open source dÃ©veloppÃ©e par Elastic pour l'analyse centralisÃ©e de logs. Elle permet de collecter, stocker, rechercher et visualiser des donnÃ©es de logs provenant de multiples sources (applications, serveurs, containers, etc.).

### Les 3 composants principaux

| Composant | RÃ´le | Fonction |
|-----------|------|----------|
| **E**lasticsearch | Moteur de recherche | Stocke et indexe les donnÃ©es, permet des recherches ultra-rapides |
| **L**ogstash | Pipeline de traitement | Collecte, transforme et envoie les donnÃ©es vers Elasticsearch |
| **K**ibana | Interface de visualisation | Permet de visualiser et d'explorer les donnÃ©es via des graphiques et dashboards |

### SchÃ©ma de fonctionnement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SOURCES DE DONNÃ‰ES                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Serveur  â”‚  â”‚   Docker  â”‚  â”‚   Apache  â”‚  â”‚Application â”‚ â”‚
â”‚  â”‚   Web     â”‚  â”‚Containers â”‚  â”‚   Logs    â”‚  â”‚   Logs     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚             â”‚
         â”‚              â”‚  Logs        â”‚             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚              â”‚
                        â–¼              â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚        LOGSTASH (Port 5000)              â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚  1. Collecte (Input)               â”‚  â”‚
         â”‚  â”‚  2. Transformation (Filter)        â”‚  â”‚
         â”‚  â”‚  3. Enrichissement                 â”‚  â”‚
         â”‚  â”‚  4. Envoi vers Elasticsearch       â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ Index JSON
                           â”‚
                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    ELASTICSEARCH (Port 9200)             â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚  â€¢ Indexation des documents        â”‚  â”‚
         â”‚  â”‚  â€¢ Stockage distribuÃ©              â”‚  â”‚
         â”‚  â”‚  â€¢ Recherche full-text             â”‚  â”‚
         â”‚  â”‚  â€¢ AgrÃ©gations et analytics        â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ API REST
                           â”‚
                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚        KIBANA (Port 5601)                â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚  â€¢ Dashboards interactifs          â”‚  â”‚
         â”‚  â”‚  â€¢ Graphiques et visualisations    â”‚  â”‚
         â”‚  â”‚  â€¢ Recherche et exploration        â”‚  â”‚
         â”‚  â”‚  â€¢ Alertes et monitoring           â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ Interface Web
                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚         NAVIGATEUR                       â”‚
         â”‚     (http://localhost:5601)              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pourquoi utiliser la stack ELK ?

| Avantage | Explication |
|----------|-------------|
| **Centralisation** | Tous vos logs au mÃªme endroit, peu importe leur source |
| **Recherche puissante** | Elasticsearch permet des recherches full-text ultra-rapides |
| **ScalabilitÃ©** | Peut gÃ©rer des tÃ©raoctets de donnÃ©es |
| **Temps rÃ©el** | Analyse et visualisation en temps rÃ©el |
| **Open source** | Gratuit et personnalisable |
| **Ã‰cosystÃ¨me riche** | Nombreuses intÃ©grations (Beats, plugins...) |
| **Visualisations** | Dashboards interactifs et graphiques variÃ©s |

### Cas d'usage typiques

| Use Case | Description |
|----------|-------------|
| **Monitoring applicatif** | Surveiller les erreurs et performances d'applications |
| **SÃ©curitÃ© (SIEM)** | DÃ©tecter les tentatives d'intrusion et anomalies |
| **Analyse business** | Analytics sur les comportements utilisateurs |
| **DevOps** | Debugging et troubleshooting d'infrastructures |
| **ConformitÃ©** | Audit et traÃ§abilitÃ© des Ã©vÃ©nements |
| **IoT** | Analyse de donnÃ©es de capteurs en temps rÃ©el |

---

## ğŸ”§ PrÃ©requis

Avant de commencer, assurez-vous d'avoir :

- âœ… Docker installÃ© (version 20.10+)
- âœ… Docker Compose installÃ© (version 2.0+)
- âœ… **Au moins 4 GB de RAM disponible** pour Docker (8 GB recommandÃ©)
- âœ… Un Ã©diteur de texte (VS Code recommandÃ©)
- âœ… Avoir lu les [concepts Docker de base](../00-introduction/02-concepts-docker.md)

**VÃ©rification rapide :**

```bash
docker --version
docker-compose --version

# VÃ©rifier la mÃ©moire allouÃ©e Ã  Docker
docker info | grep Memory
```

**âš ï¸ Important :** Elasticsearch nÃ©cessite beaucoup de mÃ©moire. Si Docker n'a que 2 GB, la stack ne dÃ©marrera pas correctement.

**Sur Windows/macOS (Docker Desktop) :**
1. Ouvrir Docker Desktop â†’ Settings â†’ Resources
2. Augmenter la RAM Ã  au moins 4 GB (idÃ©alement 8 GB)
3. Cliquer sur "Apply & Restart"

---

## ğŸ“ Ã‰tape 1 : Structure du projet

### 1.1 CrÃ©er l'arborescence

CrÃ©ez un nouveau dossier pour votre projet ELK :

```bash
# CrÃ©er le dossier principal
mkdir elk-stack
cd elk-stack

# CrÃ©er les sous-dossiers
mkdir -p elasticsearch/data
mkdir -p logstash/pipeline
mkdir -p logstash/config
mkdir -p kibana/config
mkdir -p logs/sample
```

**Votre structure sera :**

```
elk-stack/
â”œâ”€â”€ docker-compose.yml              # Configuration Docker Compose
â”œâ”€â”€ .env                            # Variables d'environnement
â”œâ”€â”€ elasticsearch/
â”‚   â””â”€â”€ data/                       # DonnÃ©es Elasticsearch (gÃ©nÃ©rÃ© automatiquement)
â”œâ”€â”€ logstash/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ logstash.yml           # Configuration Logstash
â”‚   â””â”€â”€ pipeline/
â”‚       â””â”€â”€ logstash.conf          # Pipeline de traitement
â”œâ”€â”€ kibana/
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ kibana.yml             # Configuration Kibana
â””â”€â”€ logs/
    â””â”€â”€ sample/
        â””â”€â”€ app.log                # Logs d'exemple (Ã  crÃ©er)
```

### 1.2 Pourquoi cette organisation ?

| Dossier | RÃ´le |
|---------|------|
| `elasticsearch/data/` | Stockage persistant des index et donnÃ©es |
| `logstash/pipeline/` | DÃ©finition du pipeline de traitement des logs |
| `logstash/config/` | Configuration gÃ©nÃ©rale de Logstash |
| `kibana/config/` | Configuration de Kibana |
| `logs/sample/` | Logs d'exemple pour tester la stack |

---

## ğŸ” Ã‰tape 2 : Configuration d'Elasticsearch

### 2.1 Qu'est-ce qu'Elasticsearch ?

**Elasticsearch** est un moteur de recherche et d'analyse distribuÃ© basÃ© sur Apache Lucene. Il stocke les donnÃ©es sous forme de **documents JSON** dans des **index** (Ã©quivalent des tables SQL).

**Concepts clÃ©s :**

| Concept | Ã‰quivalent SQL | Description |
|---------|----------------|-------------|
| **Index** | Base de donnÃ©es | Collection de documents similaires |
| **Document** | Ligne | UnitÃ© de donnÃ©es en JSON |
| **Field** | Colonne | PropriÃ©tÃ© d'un document |
| **Mapping** | SchÃ©ma | DÃ©finit les types de donnÃ©es |
| **Shard** | Partition | Division d'un index pour la scalabilitÃ© |

### 2.2 Configuration dans docker-compose.yml

Nous allons commencer par crÃ©er le fichier `docker-compose.yml` avec Elasticsearch :

```yaml
version: '3.8'

services:
  # ==========================================
  # SERVICE 1 : ELASTICSEARCH
  # ==========================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    container_name: elk_elasticsearch
    restart: unless-stopped

    environment:
      # Mode single-node (un seul nÅ“ud, pour dÃ©veloppement)
      - discovery.type=single-node

      # DÃ©sactiver la sÃ©curitÃ© (pour dÃ©veloppement uniquement)
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false

      # Limiter l'utilisation de mÃ©moire
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"

      # DÃ©sactiver le machine learning (Ã©conomise de la RAM)
      - xpack.ml.enabled=false

    ports:
      # API REST d'Elasticsearch
      - "9200:9200"
      # Communication inter-nÅ“uds (non utilisÃ© en single-node)
      - "9300:9300"

    volumes:
      # DonnÃ©es persistantes
      - ./elasticsearch/data:/usr/share/elasticsearch/data

    networks:
      - elk_network

    # VÃ©rification de santÃ©
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

networks:
  elk_network:
    driver: bridge
```

### 2.3 Comprendre la configuration

| ParamÃ¨tre | Explication |
|-----------|-------------|
| `discovery.type=single-node` | Mode standalone (pas de cluster) |
| `xpack.security.enabled=false` | DÃ©sactive l'authentification (dÃ©veloppement uniquement) |
| `ES_JAVA_OPTS=-Xms512m -Xmx512m` | Limite la RAM : minimum 512 MB, maximum 512 MB |
| `xpack.ml.enabled=false` | DÃ©sactive le machine learning pour Ã©conomiser des ressources |
| Port `9200` | API REST pour les requÃªtes HTTP |
| Port `9300` | Communication entre nÅ“uds Elasticsearch (non utilisÃ© ici) |

**ğŸ’¡ Note sur la mÃ©moire :**
- Production : Au moins 2-4 GB de heap JVM
- DÃ©veloppement : 512 MB suffit pour dÃ©buter
- La rÃ¨gle : heap JVM = 50% de la RAM disponible (max 32 GB)

---

## ğŸ”„ Ã‰tape 3 : Configuration de Logstash

### 3.1 Qu'est-ce que Logstash ?

**Logstash** est un pipeline de traitement de donnÃ©es open source. Il peut ingÃ©rer des donnÃ©es de multiples sources, les transformer, et les envoyer vers diverses destinations.

**Architecture d'un pipeline Logstash :**

```
INPUT â†’ FILTER â†’ OUTPUT
  â†“        â†“         â†“
Collecte  Traite  Envoie
```

**Ã‰tapes du pipeline :**

| Ã‰tape | RÃ´le | Exemples |
|-------|------|----------|
| **INPUT** | Collecte les donnÃ©es | Files, Syslog, HTTP, Beats, TCP, JDBC |
| **FILTER** | Transforme et enrichit | Parse, Grok, Mutate, Date, GeoIP |
| **OUTPUT** | Envoie vers destination | Elasticsearch, File, Kafka, S3 |

### 3.2 CrÃ©er le fichier de configuration principal

CrÃ©ez le fichier `logstash/config/logstash.yml` :

```yaml
# ==========================================
# Configuration Logstash
# ==========================================

# HÃ´te HTTP API (pour monitoring)
http.host: "0.0.0.0"

# Elasticsearch output settings
xpack.monitoring.enabled: false

# Pipeline settings
pipeline.workers: 2
pipeline.batch.size: 125
pipeline.batch.delay: 50

# Logging
log.level: info
```

### 3.3 CrÃ©er le pipeline de traitement

CrÃ©ez le fichier `logstash/pipeline/logstash.conf` :

```ruby
# ==========================================
# PIPELINE LOGSTASH - Traitement de logs
# ==========================================

input {
  # ==========================================
  # INPUT 1 : Lecture de fichiers de logs
  # ==========================================
  file {
    # Chemin vers les fichiers de logs Ã  monitorer
    path => "/usr/share/logstash/logs/sample/*.log"

    # Commencer Ã  lire depuis le dÃ©but du fichier
    start_position => "beginning"

    # Suivre les nouveaux logs en temps rÃ©el
    sincedb_path => "/dev/null"

    # Type de log (pour identification)
    type => "application_log"
  }

  # ==========================================
  # INPUT 2 : Ã‰coute TCP (optionnel)
  # ==========================================
  tcp {
    port => 5000
    codec => json_lines
    type => "tcp_json"
  }

  # ==========================================
  # INPUT 3 : HTTP (optionnel)
  # ==========================================
  http {
    port => 8080
    type => "http_json"
  }
}

filter {
  # ==========================================
  # FILTER 1 : Parsing des logs applicatifs
  # ==========================================
  if [type] == "application_log" {
    # Parser les logs au format : [TIMESTAMP] [LEVEL] [COMPONENT] Message
    grok {
      match => {
        "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{LOGLEVEL:level}\] \[%{DATA:component}\] %{GREEDYDATA:log_message}"
      }
    }

    # Convertir le timestamp en date Elasticsearch
    date {
      match => ["timestamp", "ISO8601"]
      target => "@timestamp"
    }

    # Ajouter des champs supplÃ©mentaires
    mutate {
      add_field => {
        "environment" => "development"
        "stack" => "elk"
      }

      # Supprimer le champ brut "message" (dÃ©jÃ  parsÃ©)
      remove_field => ["message"]
    }
  }

  # ==========================================
  # FILTER 2 : Enrichissement pour logs TCP/HTTP
  # ==========================================
  if [type] in ["tcp_json", "http_json"] {
    # Les donnÃ©es JSON sont dÃ©jÃ  structurÃ©es
    # Ajouter juste des mÃ©tadonnÃ©es
    mutate {
      add_field => {
        "source_type" => "%{type}"
      }
    }
  }

  # ==========================================
  # FILTER 3 : GÃ©olocalisation IP (optionnel)
  # ==========================================
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }
}

output {
  # ==========================================
  # OUTPUT 1 : Elasticsearch
  # ==========================================
  elasticsearch {
    # Adresse d'Elasticsearch (nom du service Docker)
    hosts => ["http://elasticsearch:9200"]

    # Index dynamique basÃ© sur le type et la date
    # Exemple : logs-application_log-2024.11.02
    index => "logs-%{type}-%{+YYYY.MM.dd}"

    # CrÃ©er l'index s'il n'existe pas
    manage_template => true
  }

  # ==========================================
  # OUTPUT 2 : Console (pour debug)
  # ==========================================
  stdout {
    codec => rubydebug
  }
}
```

### 3.4 Comprendre le pipeline

#### Input (Collecte)

```ruby
file {
  path => "/usr/share/logstash/logs/sample/*.log"
  start_position => "beginning"
}
```
- `path` : Chemin des fichiers Ã  monitorer (supporte les wildcards `*`)
- `start_position` : `beginning` (lire depuis le dÃ©but) ou `end` (nouveaux logs seulement)
- `sincedb_path` : Fichier qui mÃ©morise la position de lecture (ici `/dev/null` pour toujours relire)

#### Filter (Transformation)

**Plugin Grok :**
```ruby
grok {
  match => {
    "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{LOGLEVEL:level}\]..."
  }
}
```
- **Grok** : Langage de pattern matching pour extraire des donnÃ©es structurÃ©es de texte non structurÃ©
- Patterns prÃ©dÃ©finis : `TIMESTAMP_ISO8601`, `LOGLEVEL`, `IP`, `NUMBER`, etc.

**Plugin Date :**
```ruby
date {
  match => ["timestamp", "ISO8601"]
  target => "@timestamp"
}
```
- Parse une date et l'assigne au champ `@timestamp` (timestamp Elasticsearch)

**Plugin Mutate :**
```ruby
mutate {
  add_field => { "environment" => "development" }
  remove_field => ["message"]
}
```
- Ajoute, supprime ou modifie des champs

#### Output (Destination)

```ruby
elasticsearch {
  hosts => ["http://elasticsearch:9200"]
  index => "logs-%{type}-%{+YYYY.MM.dd}"
}
```
- Envoie vers Elasticsearch
- `index` : Nom de l'index (avec variables dynamiques)
- `%{type}` : Valeur du champ `type`
- `%{+YYYY.MM.dd}` : Date au format annÃ©e.mois.jour

### 3.5 Ajouter Logstash au docker-compose.yml

Ajoutez ce service dans `docker-compose.yml` :

```yaml
  # ==========================================
  # SERVICE 2 : LOGSTASH
  # ==========================================
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.1
    container_name: elk_logstash
    restart: unless-stopped

    # Attendre qu'Elasticsearch soit prÃªt
    depends_on:
      elasticsearch:
        condition: service_healthy

    environment:
      # Configuration JVM
      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"

      # Elasticsearch output
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

    ports:
      # HTTP input
      - "8080:8080"
      # TCP input
      - "5000:5000"
      # Monitoring API
      - "9600:9600"

    volumes:
      # Pipeline de traitement
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro

      # Configuration
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro

      # Logs Ã  analyser
      - ./logs/sample:/usr/share/logstash/logs/sample:ro

    networks:
      - elk_network
```

---

## ğŸ“Š Ã‰tape 4 : Configuration de Kibana

### 4.1 Qu'est-ce que Kibana ?

**Kibana** est l'interface de visualisation de la stack Elastic. C'est une application web qui permet de :
- CrÃ©er des dashboards interactifs
- Effectuer des recherches dans Elasticsearch
- CrÃ©er des graphiques et visualisations
- Configurer des alertes
- GÃ©rer les index Elasticsearch

**FonctionnalitÃ©s principales :**

| Feature | Description |
|---------|-------------|
| **Discover** | Explorer et rechercher dans les donnÃ©es |
| **Visualize** | CrÃ©er des graphiques (barres, lignes, camemberts, etc.) |
| **Dashboard** | Assembler plusieurs visualisations |
| **Canvas** | CrÃ©er des prÃ©sentations personnalisÃ©es |
| **Maps** | Visualiser des donnÃ©es gÃ©ographiques |
| **Alerts** | Configurer des notifications |

### 4.2 CrÃ©er le fichier de configuration

CrÃ©ez le fichier `kibana/config/kibana.yml` :

```yaml
# ==========================================
# Configuration Kibana
# ==========================================

# Nom du serveur (visible dans l'interface)
server.name: "kibana-elk"

# HÃ´te sur lequel Kibana Ã©coute
server.host: "0.0.0.0"

# URL d'Elasticsearch
elasticsearch.hosts: ["http://elasticsearch:9200"]

# DÃ©sactiver la sÃ©curitÃ© (dÃ©veloppement uniquement)
xpack.security.enabled: false
xpack.encryptedSavedObjects.encryptionKey: "fhjskloppd678ehkdfdlliverpoolfcr"

# Langue de l'interface
i18n.locale: "fr"

# Monitoring
monitoring.ui.enabled: true
monitoring.kibana.collection.enabled: false

# Logs
logging.dest: stdout
logging.verbose: false
```

### 4.3 Ajouter Kibana au docker-compose.yml

Ajoutez ce service dans `docker-compose.yml` :

```yaml
  # ==========================================
  # SERVICE 3 : KIBANA
  # ==========================================
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.1
    container_name: elk_kibana
    restart: unless-stopped

    # Attendre qu'Elasticsearch soit prÃªt
    depends_on:
      elasticsearch:
        condition: service_healthy

    ports:
      # Interface web Kibana
      - "5601:5601"

    volumes:
      # Configuration personnalisÃ©e
      - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro

    networks:
      - elk_network

    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
```

---

## ğŸ“ Ã‰tape 5 : CrÃ©er des logs d'exemple

### 5.1 CrÃ©er un fichier de logs

CrÃ©ez le fichier `logs/sample/app.log` avec du contenu d'exemple :

```log
[2024-11-02T10:00:00.123Z] [INFO] [AuthService] User login successful - userId: 12345, ip: 192.168.1.100
[2024-11-02T10:00:05.456Z] [INFO] [PaymentService] Payment processed - orderId: ORD-98765, amount: 99.99
[2024-11-02T10:00:10.789Z] [WARN] [DatabaseService] Slow query detected - duration: 3500ms, query: SELECT * FROM users
[2024-11-02T10:00:15.234Z] [ERROR] [EmailService] Failed to send email - recipient: user@example.com, error: SMTP timeout
[2024-11-02T10:00:20.567Z] [INFO] [CacheService] Cache cleared - keys: 150, duration: 250ms
[2024-11-02T10:00:25.890Z] [DEBUG] [APIGateway] Request received - method: POST, endpoint: /api/users, responseTime: 45ms
[2024-11-02T10:00:30.123Z] [ERROR] [FileService] File not found - path: /uploads/image.jpg, userId: 67890
[2024-11-02T10:00:35.456Z] [INFO] [NotificationService] Push notification sent - userId: 54321, deviceId: DEV-ABC123
[2024-11-02T10:00:40.789Z] [WARN] [SecurityService] Suspicious activity detected - ip: 203.0.113.50, attempts: 5
[2024-11-02T10:00:45.012Z] [INFO] [BackupService] Backup completed successfully - size: 2.5GB, duration: 180s
[2024-11-02T10:00:50.345Z] [ERROR] [APIGateway] Rate limit exceeded - ip: 198.51.100.25, endpoint: /api/search
[2024-11-02T10:00:55.678Z] [INFO] [SchedulerService] Cron job executed - job: clean-temp-files, status: success
[2024-11-02T10:01:00.901Z] [DEBUG] [ValidationService] Input validation passed - field: email, value: test@example.com
[2024-11-02T10:01:05.234Z] [WARN] [MemoryMonitor] High memory usage detected - usage: 85%, threshold: 80%
[2024-11-02T10:01:10.567Z] [INFO] [UserService] User profile updated - userId: 11111, fields: [name, avatar]
[2024-11-02T10:01:15.890Z] [ERROR] [DatabaseService] Connection pool exhausted - active: 100, max: 100
[2024-11-02T10:01:20.123Z] [INFO] [SearchService] Search query executed - term: "docker tutorial", results: 1250, duration: 85ms
[2024-11-02T10:01:25.456Z] [WARN] [SessionService] Session expired - sessionId: SESS-XYZ789, userId: 22222
[2024-11-02T10:01:30.789Z] [INFO] [AnalyticsService] Event tracked - event: page_view, page: /products, userId: 33333
[2024-11-02T10:01:35.012Z] [DEBUG] [CacheService] Cache hit - key: user:12345:profile, ttl: 3600s
```

### 5.2 Comprendre le format des logs

**Format utilisÃ© :**
```
[TIMESTAMP] [LEVEL] [COMPONENT] Message dÃ©taillÃ©
```

**Ã‰lÃ©ments :**
- `[TIMESTAMP]` : Date et heure au format ISO8601
- `[LEVEL]` : Niveau de log (INFO, WARN, ERROR, DEBUG)
- `[COMPONENT]` : Service ou composant qui gÃ©nÃ¨re le log
- `Message` : Description de l'Ã©vÃ©nement

Ce format correspond au pattern Grok dÃ©fini dans notre pipeline Logstash.

---

## ğŸ³ Ã‰tape 6 : Fichier docker-compose.yml complet

Voici le fichier `docker-compose.yml` complet avec les 3 services :

```yaml
version: '3.8'

services:
  # ==========================================
  # SERVICE 1 : ELASTICSEARCH
  # ==========================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    container_name: elk_elasticsearch
    restart: unless-stopped

    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.ml.enabled=false

    ports:
      - "9200:9200"
      - "9300:9300"

    volumes:
      - ./elasticsearch/data:/usr/share/elasticsearch/data

    networks:
      - elk_network

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # ==========================================
  # SERVICE 2 : LOGSTASH
  # ==========================================
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.1
    container_name: elk_logstash
    restart: unless-stopped

    depends_on:
      elasticsearch:
        condition: service_healthy

    environment:
      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

    ports:
      - "8080:8080"
      - "5000:5000"
      - "9600:9600"

    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logs/sample:/usr/share/logstash/logs/sample:ro

    networks:
      - elk_network

  # ==========================================
  # SERVICE 3 : KIBANA
  # ==========================================
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.1
    container_name: elk_kibana
    restart: unless-stopped

    depends_on:
      elasticsearch:
        condition: service_healthy

    ports:
      - "5601:5601"

    volumes:
      - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro

    networks:
      - elk_network

    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

# ==========================================
# RÃ‰SEAU PARTAGÃ‰
# ==========================================
networks:
  elk_network:
    driver: bridge
```

---

## â–¶ï¸ Ã‰tape 7 : DÃ©marrer la stack

### 7.1 Permissions (Linux uniquement)

Sur Linux, Elasticsearch nÃ©cessite des permissions spÃ©cifiques :

```bash
# Donner les droits au dossier de donnÃ©es
sudo chown -R 1000:1000 elasticsearch/data

# Ou autoriser tout le monde (moins sÃ©curisÃ©)
chmod -R 777 elasticsearch/data
```

### 7.2 DÃ©marrage de la stack

```bash
# Depuis le dossier elk-stack
docker-compose up -d
```

**Ce qui se passe :**
1. TÃ©lÃ©chargement des images (premiÃ¨re fois uniquement, ~2 GB)
2. CrÃ©ation du rÃ©seau `elk_network`
3. DÃ©marrage d'Elasticsearch
4. Attente que le healthcheck d'Elasticsearch passe au vert
5. DÃ©marrage de Logstash (commence Ã  ingÃ©rer les logs)
6. DÃ©marrage de Kibana

**â³ Patience :** Le premier dÃ©marrage peut prendre 3-5 minutes.

### 7.3 VÃ©rifier que tout fonctionne

```bash
# Voir les conteneurs actifs
docker-compose ps

# RÃ©sultat attendu :
# NAME               STATE           PORTS
# elk_elasticsearch  Up (healthy)    9200/tcp, 9300/tcp
# elk_logstash       Up              5000/tcp, 8080/tcp, 9600/tcp
# elk_kibana         Up (healthy)    5601/tcp
```

```bash
# Voir les logs en temps rÃ©el
docker-compose logs -f

# Logs d'un service spÃ©cifique
docker-compose logs -f elasticsearch
docker-compose logs -f logstash
docker-compose logs -f kibana
```

### 7.4 VÃ©rifier Elasticsearch

```bash
# Health check
curl http://localhost:9200/_cluster/health?pretty

# Informations sur le cluster
curl http://localhost:9200

# Lister les index crÃ©Ã©s
curl http://localhost:9200/_cat/indices?v
```

**RÃ©ponse attendue pour les index :**
```
health status index                          docs.count
yellow open   logs-application_log-2024.11.02    20
```

---

## ğŸ“Š Ã‰tape 8 : Utiliser Kibana

### 8.1 AccÃ©der Ã  Kibana

Ouvrez votre navigateur et allez sur :

```
http://localhost:5601
```

**Au premier dÃ©marrage :**
- Kibana peut mettre 1-2 minutes Ã  Ãªtre complÃ¨tement prÃªt
- Si vous voyez "Kibana server is not ready yet", patientez et rechargez

### 8.2 CrÃ©er un Index Pattern

Un **Index Pattern** indique Ã  Kibana quels index Elasticsearch interroger.

**Ã‰tapes :**

1. **Cliquer sur le menu hamburger (â˜°)** en haut Ã  gauche
2. **Naviguer vers** : Management > Stack Management
3. **Dans le menu de gauche** : Kibana > Index Patterns (ou Data Views dans les versions rÃ©centes)
4. **Cliquer sur** "Create index pattern" ou "Create data view"
5. **DÃ©finir le pattern** :
   - Name : `logs-*`
   - Index pattern : `logs-*` (correspond Ã  tous les index commenÃ§ant par "logs-")
6. **Cliquer sur** "Next step"
7. **Time field** : SÃ©lectionner `@timestamp`
8. **Cliquer sur** "Create index pattern"

**âœ… Votre index pattern est crÃ©Ã© !** Kibana peut maintenant interroger vos logs.

### 8.3 Explorer les donnÃ©es (Discover)

1. **Menu (â˜°)** â†’ Analytics â†’ **Discover**
2. **SÃ©lectionner l'index pattern** "logs-*" dans le menu dÃ©roulant en haut
3. **Vous devriez voir vos logs** apparaÃ®tre dans la timeline et la liste

**Interface Discover :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Filtres]  [PÃ©riode]  [RafraÃ®chir]                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ğŸ“Š Timeline (graphique temporel)                       â”‚
â”‚     â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆ                                            â”‚
â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Champs disponibles:                 Table des logs      â”‚
â”‚ â€¢ @timestamp                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â€¢ level                             â”‚ @timestamp       â”‚â”‚
â”‚ â€¢ component                         â”‚ 2024-11-02 10:00 â”‚â”‚
â”‚ â€¢ log_message                       â”‚ [INFO]...        â”‚â”‚
â”‚ â€¢ ...                               â”‚                  â”‚â”‚
â”‚                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Actions utiles :**

- **Filtrer par niveau** : Cliquer sur un champ (ex: `level`) dans la colonne de gauche â†’ `+` (ajouter filtre)
- **Recherche** : Utiliser la barre de recherche en haut (syntaxe Lucene ou KQL)
  - Exemple : `level: ERROR`
  - Exemple : `component: "EmailService"`
- **PÃ©riode** : Ajuster la pÃ©riode en haut Ã  droite (Last 15 minutes, Today, Last 7 days...)
- **RafraÃ®chir** : Cliquer sur "Refresh" pour voir les nouveaux logs

### 8.4 CrÃ©er des visualisations

**Exemple : Graphique des niveaux de log**

1. **Menu (â˜°)** â†’ Analytics â†’ **Visualize Library**
2. **Cliquer sur** "Create visualization"
3. **Choisir le type** : "Vertical bar" (graphique Ã  barres verticales)
4. **SÃ©lectionner la source** : "logs-*"
5. **Configuration** :
   - **Horizontal axis (Axe X)** :
     - Aggregation : "Terms"
     - Field : "level.keyword"
     - Order by : "Metric: Count"
   - **Vertical axis (Axe Y)** :
     - Aggregation : "Count"
6. **Cliquer sur** "Update" (bouton â–¶ï¸ en haut)
7. **Voir le graphique** : Barres reprÃ©sentant le nombre de logs par niveau (INFO, WARN, ERROR, DEBUG)
8. **Sauvegarder** : Cliquer sur "Save" en haut Ã  droite, donner un nom ("Logs par niveau")

**Autres visualisations intÃ©ressantes :**

| Type | UtilitÃ© | Configuration |
|------|---------|---------------|
| **Pie Chart** | RÃ©partition des composants | Terms sur `component.keyword` |
| **Line Chart** | Ã‰volution temporelle | Date histogram sur `@timestamp` |
| **Metric** | Compteur simple | Count des documents |
| **Data Table** | Tableau dÃ©taillÃ© | Multiple Metrics et Buckets |

### 8.5 CrÃ©er un Dashboard

Un **Dashboard** assemble plusieurs visualisations sur une seule page.

**Ã‰tapes :**

1. **Menu (â˜°)** â†’ Analytics â†’ **Dashboard**
2. **Cliquer sur** "Create new dashboard"
3. **Cliquer sur** "Add" (ou "Add from library")
4. **SÃ©lectionner vos visualisations** crÃ©Ã©es prÃ©cÃ©demment
5. **Organiser** : Glisser-dÃ©poser et redimensionner les panneaux
6. **Sauvegarder** : Cliquer sur "Save" en haut Ã  droite, donner un nom ("Dashboard Logs Application")

**Exemple de layout :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dashboard : Logs Application                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 â”‚                                â”‚
â”‚  ğŸ“Š Logs par    â”‚  ğŸ¥§ Logs par                   â”‚
â”‚     niveau      â”‚     composant                  â”‚
â”‚                 â”‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  ğŸ“ˆ Ã‰volution temporelle des logs                â”‚
â”‚                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“‹ Tableau des derniers logs ERROR              â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Ã‰tape 9 : RequÃªtes et recherches

### 9.1 RequÃªtes Elasticsearch (API REST)

Elasticsearch expose une API REST puissante. Voici des exemples de requÃªtes :

**1. Rechercher tous les logs ERROR :**

```bash
curl -X GET "http://localhost:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match": {
      "level": "ERROR"
    }
  }
}'
```

**2. Compter les logs par niveau :**

```bash
curl -X GET "http://localhost:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "size": 0,
  "aggs": {
    "by_level": {
      "terms": {
        "field": "level.keyword"
      }
    }
  }
}'
```

**3. Logs des derniÃ¨res 24 heures :**

```bash
curl -X GET "http://localhost:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "range": {
      "@timestamp": {
        "gte": "now-24h"
      }
    }
  }
}'
```

### 9.2 KQL (Kibana Query Language)

Dans Kibana (Discover), vous pouvez utiliser **KQL** pour des recherches simples :

**Exemples de requÃªtes KQL :**

| RequÃªte | RÃ©sultat |
|---------|----------|
| `level: ERROR` | Tous les logs de niveau ERROR |
| `component: "EmailService"` | Logs du composant EmailService |
| `level: ERROR AND component: "DatabaseService"` | Logs ERROR du DatabaseService |
| `level: (ERROR OR WARN)` | Logs ERROR ou WARN |
| `log_message: *timeout*` | Logs contenant le mot "timeout" |
| `NOT level: DEBUG` | Tous les logs sauf DEBUG |

### 9.3 Lucene Query Syntax

Si vous dÃ©sactivez KQL dans Kibana, vous pouvez utiliser la syntaxe Lucene :

```
level:ERROR AND component:EmailService
level:(ERROR OR WARN)
log_message:timeout AND level:ERROR
@timestamp:[now-1h TO now]
```

---

## ğŸ“Š Ã‰tape 10 : Envoyer des logs en temps rÃ©el

### 10.1 Via TCP (JSON)

Logstash Ã©coute sur le port 5000 (TCP) :

```bash
# Envoyer un log JSON via TCP
echo '{"level":"INFO","component":"TestService","message":"Test depuis TCP"}' | nc localhost 5000
```

### 10.2 Via HTTP (JSON)

Logstash Ã©coute sur le port 8080 (HTTP) :

```bash
# Envoyer un log JSON via HTTP
curl -X POST "http://localhost:8080" -H 'Content-Type: application/json' -d'
{
  "level": "WARN",
  "component": "MonitoringService",
  "message": "CPU usage above 80%",
  "cpu_usage": 85.5,
  "timestamp": "2024-11-02T12:00:00.000Z"
}'
```

### 10.3 Ajouter des logs au fichier

Vous pouvez continuer Ã  ajouter des lignes au fichier `logs/sample/app.log` :

```bash
# Ajouter une nouvelle ligne
echo "[$(date -Iseconds)] [INFO] [TestService] Test log entry" >> logs/sample/app.log
```

Logstash dÃ©tectera automatiquement le nouveau log et l'indexera dans Elasticsearch.

---

## ğŸ› ï¸ Ã‰tape 11 : Gestion et maintenance

### 11.1 Commandes utiles

```bash
# Voir les conteneurs actifs
docker-compose ps

# Logs de tous les services
docker-compose logs

# Logs en temps rÃ©el
docker-compose logs -f

# Logs d'un service spÃ©cifique
docker-compose logs -f logstash

# Statistiques de ressources
docker stats elk_elasticsearch elk_logstash elk_kibana

# ArrÃªter tous les services (donnÃ©es conservÃ©es)
docker-compose stop

# RedÃ©marrer tous les services
docker-compose start

# RedÃ©marrer un service spÃ©cifique
docker-compose restart logstash
```

### 11.2 Gestion des index Elasticsearch

**Lister les index :**
```bash
curl -X GET "http://localhost:9200/_cat/indices?v&s=index"
```

**Supprimer un index :**
```bash
curl -X DELETE "http://localhost:9200/logs-application_log-2024.11.01"
```

**Supprimer tous les index logs-* :**
```bash
curl -X DELETE "http://localhost:9200/logs-*"
```

**Voir l'espace disque utilisÃ© :**
```bash
curl -X GET "http://localhost:9200/_cat/allocation?v"
```

### 11.3 RÃ©indexation

Si vous modifiez le pipeline Logstash, vous devrez peut-Ãªtre rÃ©indexer :

```bash
# 1. Supprimer les anciens index
curl -X DELETE "http://localhost:9200/logs-*"

# 2. RedÃ©marrer Logstash
docker-compose restart logstash

# Logstash va relire les fichiers de logs et rÃ©indexer
```

---

## ğŸ›‘ Ã‰tape 12 : ArrÃªt et nettoyage

### 12.1 ArrÃªter proprement

```bash
# ArrÃªter tous les services (donnÃ©es conservÃ©es)
docker-compose stop

# RedÃ©marrer plus tard
docker-compose start
```

### 12.2 Suppression complÃ¨te

```bash
# ArrÃªter et supprimer les conteneurs
docker-compose down

# Supprimer les donnÃ©es Elasticsearch (âš ï¸ IRRÃ‰VERSIBLE)
rm -rf elasticsearch/data/*

# Supprimer les images Docker (optionnel)
docker rmi docker.elastic.co/elasticsearch/elasticsearch:8.11.1
docker rmi docker.elastic.co/logstash/logstash:8.11.1
docker rmi docker.elastic.co/kibana/kibana:8.11.1

# Supprimer le rÃ©seau
docker network rm elk-stack_elk_network
```

---

## ğŸ› DÃ©pannage

### ProblÃ¨me 1 : Elasticsearch ne dÃ©marre pas

**SymptÃ´me :** `elk_elasticsearch` se redÃ©marre en boucle ou s'arrÃªte immÃ©diatement.

**Solutions :**

1. **VÃ©rifier la mÃ©moire allouÃ©e Ã  Docker :**
   ```bash
   docker info | grep Memory
   # Doit afficher au moins 4 GB
   ```
   - Windows/macOS : Docker Desktop â†’ Settings â†’ Resources â†’ Augmenter la RAM

2. **VÃ©rifier les logs Elasticsearch :**
   ```bash
   docker-compose logs elasticsearch
   ```
   - Cherchez des erreurs comme "OutOfMemoryError" ou "vm.max_map_count"

3. **Linux : Augmenter vm.max_map_count :**
   ```bash
   sudo sysctl -w vm.max_map_count=262144

   # Permanent (survit aux redÃ©marrages)
   echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf
   ```

4. **VÃ©rifier les permissions du dossier data :**
   ```bash
   sudo chown -R 1000:1000 elasticsearch/data
   ```

### ProblÃ¨me 2 : Logstash ne traite pas les logs

**SymptÃ´me :** Les logs ne s'affichent pas dans Kibana.

**Solutions :**

1. **VÃ©rifier que Logstash est dÃ©marrÃ© :**
   ```bash
   docker-compose ps
   # elk_logstash doit Ãªtre "Up"
   ```

2. **VÃ©rifier les logs Logstash :**
   ```bash
   docker-compose logs logstash | grep -i error
   ```

3. **VÃ©rifier que le fichier de logs existe et est accessible :**
   ```bash
   docker exec -it elk_logstash ls -la /usr/share/logstash/logs/sample/
   ```

4. **Tester le pipeline manuellement :**
   ```bash
   # Ajouter une nouvelle ligne au fichier
   echo "[$(date -Iseconds)] [ERROR] [TestService] Manual test log" >> logs/sample/app.log

   # Voir les logs Logstash en temps rÃ©el
   docker-compose logs -f logstash
   ```

5. **VÃ©rifier qu'Elasticsearch reÃ§oit les donnÃ©es :**
   ```bash
   curl -X GET "http://localhost:9200/_cat/indices?v"
   # VÃ©rifiez que les index logs-* existent
   ```

### ProblÃ¨me 3 : Kibana "Unable to connect to Elasticsearch"

**SymptÃ´me :** Kibana affiche un message d'erreur de connexion.

**Solutions :**

1. **VÃ©rifier qu'Elasticsearch est accessible :**
   ```bash
   curl http://localhost:9200
   # Doit retourner un JSON avec des infos sur le cluster
   ```

2. **VÃ©rifier la configuration de Kibana :**
   ```bash
   cat kibana/config/kibana.yml | grep elasticsearch.hosts
   # Doit Ãªtre : http://elasticsearch:9200
   ```

3. **RedÃ©marrer Kibana :**
   ```bash
   docker-compose restart kibana
   ```

4. **VÃ©rifier le rÃ©seau Docker :**
   ```bash
   docker network inspect elk-stack_elk_network
   # Les 3 conteneurs doivent Ãªtre listÃ©s
   ```

### ProblÃ¨me 4 : Index pattern ne trouve pas d'index

**SymptÃ´me :** "No matching indices found" lors de la crÃ©ation de l'index pattern.

**Solutions :**

1. **VÃ©rifier que des index existent dans Elasticsearch :**
   ```bash
   curl -X GET "http://localhost:9200/_cat/indices?v"
   ```
   - Si aucun index `logs-*` n'apparaÃ®t, Logstash n'a pas encore traitÃ© de logs

2. **VÃ©rifier que le fichier app.log contient des donnÃ©es :**
   ```bash
   cat logs/sample/app.log
   ```

3. **RedÃ©marrer Logstash pour forcer le retraitement :**
   ```bash
   docker-compose restart logstash
   ```

4. **Attendre quelques secondes** et rafraÃ®chir Kibana

### ProblÃ¨me 5 : "Disk watermark exceeded"

**SymptÃ´me :** Elasticsearch refuse d'indexer de nouvelles donnÃ©es.

**Cause :** Le disque est plein Ã  plus de 90%.

**Solutions :**

1. **VÃ©rifier l'espace disque :**
   ```bash
   df -h
   ```

2. **Supprimer les vieux index :**
   ```bash
   # Supprimer les index de plus de 7 jours
   curl -X DELETE "http://localhost:9200/logs-*-2024.10.*"
   ```

3. **Augmenter le seuil (temporaire, pour dÃ©veloppement) :**
   ```bash
   curl -X PUT "http://localhost:9200/_cluster/settings" -H 'Content-Type: application/json' -d'
   {
     "transient": {
       "cluster.routing.allocation.disk.watermark.low": "95%",
       "cluster.routing.allocation.disk.watermark.high": "97%"
     }
   }'
   ```

---

## âœ… RÃ©capitulatif

### Ce que vous avez appris

- âœ… Comprendre l'architecture et le rÃ´le de chaque composant ELK
- âœ… DÃ©ployer Elasticsearch, Logstash et Kibana avec Docker Compose
- âœ… CrÃ©er un pipeline Logstash pour collecter et transformer des logs
- âœ… Utiliser Grok pour parser des logs non structurÃ©s
- âœ… Indexer des donnÃ©es dans Elasticsearch
- âœ… CrÃ©er des index patterns dans Kibana
- âœ… Explorer des logs avec Discover
- âœ… CrÃ©er des visualisations et des dashboards
- âœ… Effectuer des recherches avec KQL et l'API Elasticsearch

### Technologies maÃ®trisÃ©es

| Technologie | Version | RÃ´le |
|-------------|---------|------|
| Elasticsearch | 8.11.1 | Moteur de recherche et stockage |
| Logstash | 8.11.1 | Pipeline de traitement de donnÃ©es |
| Kibana | 8.11.1 | Interface de visualisation |
| Docker | 20.10+ | Conteneurisation |

### Fichiers crÃ©Ã©s

```
elk-stack/
â”œâ”€â”€ docker-compose.yml              # Orchestration des 3 services
â”œâ”€â”€ elasticsearch/
â”‚   â””â”€â”€ data/                       # DonnÃ©es indexÃ©es (persistantes)
â”œâ”€â”€ logstash/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ logstash.yml           # Config Logstash
â”‚   â””â”€â”€ pipeline/
â”‚       â””â”€â”€ logstash.conf          # Pipeline de traitement
â”œâ”€â”€ kibana/
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ kibana.yml             # Config Kibana
â””â”€â”€ logs/
    â””â”€â”€ sample/
        â””â”€â”€ app.log                # Logs d'exemple
```

### Ports utilisÃ©s

| Service | Port | Usage |
|---------|------|-------|
| Elasticsearch | 9200 | API REST |
| Elasticsearch | 9300 | Communication inter-nÅ“uds |
| Logstash | 5000 | Input TCP |
| Logstash | 8080 | Input HTTP |
| Logstash | 9600 | Monitoring API |
| Kibana | 5601 | Interface web |

### Commandes essentielles

```bash
# DÃ©marrer la stack
docker-compose up -d

# Voir les logs
docker-compose logs -f

# ArrÃªter (donnÃ©es conservÃ©es)
docker-compose stop

# RedÃ©marrer
docker-compose start

# Supprimer tout
docker-compose down
rm -rf elasticsearch/data

# API Elasticsearch
curl http://localhost:9200/_cat/indices?v

# AccÃ¨s Kibana
http://localhost:5601
```

---

## ğŸš€ Pour aller plus loin

### Extensions possibles

1. **Ajouter Beats** (collecteurs lÃ©gers)
   - **Filebeat** : Collecter des logs de fichiers
   - **Metricbeat** : MÃ©triques systÃ¨me et applicatives
   - **Packetbeat** : Analyse rÃ©seau
   - **Heartbeat** : Monitoring de disponibilitÃ©

2. **Activer la sÃ©curitÃ©** (production)
   - Authentification (users/passwords)
   - Chiffrement TLS/SSL
   - API keys

3. **Configurer des alertes**
   - DÃ©tection d'anomalies
   - Notifications (email, Slack, webhook)
   - Watcher (alerting d'Elastic)

4. **Optimiser les performances**
   - Sharding et replicas
   - Index Lifecycle Management (ILM)
   - Index templates
   - Compression

5. **Ajouter Grafana**
   - Alternative Ã  Kibana pour les visualisations
   - IntÃ©gration avec Elasticsearch

6. **Cluster multi-nÅ“uds**
   - Haute disponibilitÃ©
   - Load balancing
   - Failover automatique

### ScÃ©narios avancÃ©s

| ScÃ©nario | Description |
|----------|-------------|
| **Log aggregation** | Collecter les logs de 100+ serveurs |
| **SIEM** | Security Information and Event Management |
| **APM** | Application Performance Monitoring |
| **Observability** | Logs + Metrics + Traces (Elastic Observability) |
| **Business analytics** | Analyser les comportements utilisateurs |

### Ressources complÃ©mentaires

- ğŸ“– [Documentation Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)
- ğŸ“– [Documentation Logstash](https://www.elastic.co/guide/en/logstash/current/index.html)
- ğŸ“– [Documentation Kibana](https://www.elastic.co/guide/en/kibana/current/index.html)
- ğŸ“– [Grok patterns](https://github.com/elastic/logstash/blob/main/patterns/grok-patterns)
- ğŸ“ [Elastic training](https://www.elastic.co/training/)
- ğŸ’¬ [Discuss forum](https://discuss.elastic.co/)

---

## ğŸ‰ FÃ©licitations !

Vous avez maintenant une **stack ELK complÃ¨te et fonctionnelle** ! Cette base vous permet de :

- ğŸ“Š Centraliser et analyser vos logs
- ğŸ” Effectuer des recherches ultra-rapides
- ğŸ“ˆ CrÃ©er des dashboards interactifs
- ğŸš¨ DÃ©tecter des anomalies et erreurs
- ğŸ“‰ Suivre des KPIs en temps rÃ©el
- ğŸ³ DÃ©ployer facilement avec Docker

**Prochain pas :** Explorez d'autres configurations du guide !

â¡ï¸ [Stack LAMP (Apache + MariaDB + PHP)](01-stack-lamp.md)
â¡ï¸ [Stack MEAN (MongoDB + Express + Angular + Node)](02-stack-mean.md)
â¡ï¸ [Environnement de dÃ©veloppement complet](04-env-dev-complet.md)

---

ğŸ” Retour au [Sommaire](/SOMMAIRE.md)
