# 7.3 Cluster Cassandra simple (3 n≈ìuds)

üîù Retour au [Sommaire](/SOMMAIRE.md)

---

## üìã Introduction

Dans les fiches pr√©c√©dentes, nous avons travaill√© avec un **n≈ìud unique** de Cassandra. C'est parfait pour le d√©veloppement, mais Cassandra est con√ßu pour fonctionner en **cluster** (plusieurs n≈ìuds).

### Qu'est-ce qu'un cluster Cassandra ?

Un **cluster** est un ensemble de **n≈ìuds** (serveurs) Cassandra qui travaillent ensemble pour :
- üîÑ **R√©pliquer les donn√©es** entre plusieurs n≈ìuds
- ‚ö° **Haute disponibilit√©** : Si un n≈ìud tombe, les autres continuent
- üìà **Scalabilit√©** : Ajouter des n≈ìuds pour g√©rer plus de donn√©es
- üöÄ **Performances** : Distribuer la charge sur plusieurs serveurs

### Architecture d'un cluster 3 n≈ìuds

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Cluster "DevCluster"               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  N≈ìud 1  ‚îÇ  ‚îÇ  N≈ìud 2  ‚îÇ  ‚îÇ  N≈ìud 3  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ172.20.0.2‚îÇ  ‚îÇ172.20.0.3‚îÇ  ‚îÇ172.20.0.4‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Seed   ‚îÇ  ‚îÇ          ‚îÇ  ‚îÇ          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ       ‚îÇ             ‚îÇ             ‚îÇ        ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ          Communication interne             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Pourquoi 3 n≈ìuds ?**
- Minimum recommand√© pour la r√©plication (Replication Factor = 3)
- Assure la haute disponibilit√© (perte d'un n≈ìud tol√©r√©e)
- Bon √©quilibre pour l'apprentissage (pas trop lourd)

---

## üéØ Ce que vous allez apprendre

√Ä la fin de cette fiche, vous saurez :
- ‚úÖ Cr√©er un cluster Cassandra de 3 n≈ìuds avec Docker Compose
- ‚úÖ Configurer les n≈ìuds seeds (points d'entr√©e du cluster)
- ‚úÖ Assigner des IPs fixes √† chaque n≈ìud
- ‚úÖ V√©rifier l'√©tat du cluster avec `nodetool`
- ‚úÖ Cr√©er un keyspace avec r√©plication sur 3 n≈ìuds
- ‚úÖ Tester la r√©silience (arr√™t d'un n≈ìud)
- ‚úÖ Comprendre les concepts de r√©plication et de consistance

---

## üì¶ Pr√©requis

Avant de commencer, assurez-vous d'avoir :

- **Docker** install√© (version 20.10+)
- **Docker Compose** install√© (version 2.0+)
- Au moins **4 GB de RAM disponible** (3 n≈ìuds = ressources √ó 3)
- Avoir lu les fiches pr√©c√©dentes :
  - [7.1 - Configuration basique](01-config-noeud-unique.md)
  - [7.2 - Configuration avec IP fixe](02-config-ip-fixe.md)

**V√©rification rapide :**
```bash
docker --version
docker-compose --version
```

---

## üåê √âtape 1 : Cr√©ation du r√©seau Docker

Cr√©ez un r√©seau d√©di√© pour le cluster :

```bash
docker network create --subnet=172.20.0.0/16 cassandra_cluster_net
```

**V√©rification :**
```bash
docker network ls | grep cassandra_cluster_net
```

---

## üìù √âtape 2 : Configuration du `docker-compose.yml`

Cr√©ez un nouveau dossier pour ce projet :

```bash
mkdir cassandra-cluster
cd cassandra-cluster
```

Cr√©ez un fichier `docker-compose.yml` avec le contenu suivant :

```yaml
version: '3.8'

services:
  # ========================================
  # N≈íUD 1 - Seed Node (Point d'entr√©e)
  # ========================================
  cassandra-seed:
    image: cassandra:4.1
    container_name: cassandra-seed
    hostname: cassandra-seed
    restart: unless-stopped

    environment:
      # Configuration du cluster
      CASSANDRA_CLUSTER_NAME: 'DevCluster'
      CASSANDRA_DC: 'datacenter1'
      CASSANDRA_RACK: 'rack1'
      CASSANDRA_ENDPOINT_SNITCH: 'GossipingPropertyFileSnitch'

      # Configuration r√©seau
      CASSANDRA_LISTEN_ADDRESS: 'auto'
      CASSANDRA_RPC_ADDRESS: '0.0.0.0'
      CASSANDRA_BROADCAST_ADDRESS: '172.20.0.2'
      CASSANDRA_BROADCAST_RPC_ADDRESS: '172.20.0.2'

      # SEED NODE : Ce n≈ìud est le point d'entr√©e du cluster
      CASSANDRA_SEEDS: '172.20.0.2'

      # Optimisations pour le d√©veloppement
      MAX_HEAP_SIZE: '512M'
      HEAP_NEWSIZE: '100M'

    ports:
      # Port CQL pour connexion externe
      - "9042:9042"

    volumes:
      - cassandra_seed_data:/var/lib/cassandra

    networks:
      cassandra_cluster_net:
        ipv4_address: 172.20.0.2

    healthcheck:
      test: ["CMD-SHELL", "nodetool status"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s

  # ========================================
  # N≈íUD 2
  # ========================================
  cassandra-node2:
    image: cassandra:4.1
    container_name: cassandra-node2
    hostname: cassandra-node2
    restart: unless-stopped

    environment:
      CASSANDRA_CLUSTER_NAME: 'DevCluster'
      CASSANDRA_DC: 'datacenter1'
      CASSANDRA_RACK: 'rack1'
      CASSANDRA_ENDPOINT_SNITCH: 'GossipingPropertyFileSnitch'

      CASSANDRA_LISTEN_ADDRESS: 'auto'
      CASSANDRA_RPC_ADDRESS: '0.0.0.0'
      CASSANDRA_BROADCAST_ADDRESS: '172.20.0.3'
      CASSANDRA_BROADCAST_RPC_ADDRESS: '172.20.0.3'

      # Ce n≈ìud rejoint via le seed
      CASSANDRA_SEEDS: '172.20.0.2'

      MAX_HEAP_SIZE: '512M'
      HEAP_NEWSIZE: '100M'

    volumes:
      - cassandra_node2_data:/var/lib/cassandra

    networks:
      cassandra_cluster_net:
        ipv4_address: 172.20.0.3

    # Attend que le seed soit pr√™t avant de d√©marrer
    depends_on:
      cassandra-seed:
        condition: service_healthy

    healthcheck:
      test: ["CMD-SHELL", "nodetool status"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s

  # ========================================
  # N≈íUD 3
  # ========================================
  cassandra-node3:
    image: cassandra:4.1
    container_name: cassandra-node3
    hostname: cassandra-node3
    restart: unless-stopped

    environment:
      CASSANDRA_CLUSTER_NAME: 'DevCluster'
      CASSANDRA_DC: 'datacenter1'
      CASSANDRA_RACK: 'rack1'
      CASSANDRA_ENDPOINT_SNITCH: 'GossipingPropertyFileSnitch'

      CASSANDRA_LISTEN_ADDRESS: 'auto'
      CASSANDRA_RPC_ADDRESS: '0.0.0.0'
      CASSANDRA_BROADCAST_ADDRESS: '172.20.0.4'
      CASSANDRA_BROADCAST_RPC_ADDRESS: '172.20.0.4'

      # Ce n≈ìud rejoint via le seed
      CASSANDRA_SEEDS: '172.20.0.2'

      MAX_HEAP_SIZE: '512M'
      HEAP_NEWSIZE: '100M'

    volumes:
      - cassandra_node3_data:/var/lib/cassandra

    networks:
      cassandra_cluster_net:
        ipv4_address: 172.20.0.4

    # Attend que le seed soit pr√™t avant de d√©marrer
    depends_on:
      cassandra-seed:
        condition: service_healthy

    healthcheck:
      test: ["CMD-SHELL", "nodetool status"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s

# ========================================
# VOLUMES (un par n≈ìud)
# ========================================
volumes:
  cassandra_seed_data:
    driver: local
  cassandra_node2_data:
    driver: local
  cassandra_node3_data:
    driver: local

# ========================================
# R√âSEAU
# ========================================
networks:
  cassandra_cluster_net:
    external: true
```

---

## üîç Explications d√©taill√©es

### Structure du cluster

| N≈ìud | IP | R√¥le | Description |
|------|-----|------|-------------|
| **cassandra-seed** | `172.20.0.2` | Seed Node | Point d'entr√©e, premier √† d√©marrer |
| **cassandra-node2** | `172.20.0.3` | Node | Rejoint le cluster via le seed |
| **cassandra-node3** | `172.20.0.4` | Node | Rejoint le cluster via le seed |

### Variables d'environnement importantes

| Variable | Valeur | Description |
|----------|--------|-------------|
| `CASSANDRA_SEEDS` | `172.20.0.2` | Adresse du(des) n≈ìud(s) seed |
| `CASSANDRA_ENDPOINT_SNITCH` | `GossipingPropertyFileSnitch` | Strat√©gie de topologie du cluster |
| `MAX_HEAP_SIZE` | `512M` | M√©moire JVM (r√©duite pour le dev) |
| `HEAP_NEWSIZE` | `100M` | M√©moire pour les nouveaux objets |

### Ordre de d√©marrage

```yaml
depends_on:
  cassandra-seed:
    condition: service_healthy
```

- Le **seed** d√©marre en premier
- Les **n≈ìuds 2 et 3** attendent que le seed soit "healthy"
- Cela garantit un d√©marrage ordonn√© du cluster

### Volumes s√©par√©s

Chaque n≈ìud a son propre volume :
- `cassandra_seed_data`
- `cassandra_node2_data`
- `cassandra_node3_data`

**Pourquoi ?** Chaque n≈ìud stocke une partie diff√©rente des donn√©es (distribution).

---

## ‚ñ∂Ô∏è √âtape 3 : Lancement du cluster

### D√©marrer les 3 n≈ìuds

```bash
docker-compose up -d
```

**‚è≥ Patience :** Le d√©marrage complet d'un cluster prend **3 √† 5 minutes**.

### Suivre les logs

**Logs du seed :**
```bash
docker-compose logs -f cassandra-seed
```

**Attendez de voir :**
```
Starting listening for CQL clients on /0.0.0.0:9042
Node is now in NORMAL state
```

**Logs des autres n≈ìuds :**
```bash
docker-compose logs -f cassandra-node2
docker-compose logs -f cassandra-node3
```

**Appuyez sur Ctrl+C** pour sortir des logs.

---

## ‚úÖ √âtape 4 : V√©rification du cluster

### M√©thode 1 : √âtat des conteneurs

```bash
docker-compose ps
```

**R√©sultat attendu :**
```
NAME                STATE      STATUS
cassandra-seed      running    healthy
cassandra-node2     running    healthy
cassandra-node3     running    healthy
```

‚úÖ Tous doivent √™tre `running` et `healthy`.

### M√©thode 2 : Commande `nodetool status`

C'est **LA** commande pour v√©rifier l'√©tat du cluster :

```bash
docker exec -it cassandra-seed nodetool status
```

**R√©sultat attendu :**
```
Datacenter: datacenter1
=======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address      Load       Tokens  Owns (effective)  Host ID                               Rack
UN  172.20.0.2   108.5 KiB  16      66.7%             abc123...                             rack1
UN  172.20.0.3   104.2 KiB  16      66.7%             def456...                             rack1
UN  172.20.0.4   107.8 KiB  16      66.6%             ghi789...                             rack1
```

**Interpr√©tation :**

| Colonne | Description | Valeur attendue |
|---------|-------------|-----------------|
| **Status** | U = Up (actif) | `U` pour tous |
| **State** | N = Normal | `N` pour tous |
| **Address** | IP du n≈ìud | 172.20.0.2/3/4 |
| **Tokens** | Nombre de tokens | 16 (par d√©faut) |
| **Owns** | % des donn√©es | ~33% chacun |

‚úÖ **Cluster op√©rationnel** si tous les n≈ìuds sont `UN` (Up Normal).

### M√©thode 3 : Information du cluster

```bash
docker exec -it cassandra-seed nodetool describecluster
```

**R√©sultat :**
```
Cluster Information:
    Name: DevCluster
    Snitch: org.apache.cassandra.locator.GossipingPropertyFileSnitch
    DynamicEndPointSnitch: enabled
    Partitioner: org.apache.cassandra.dht.Murmur3Partitioner
    Schema versions:
        abc123: [172.20.0.2, 172.20.0.3, 172.20.0.4]
```

‚úÖ Les **3 n≈ìuds** doivent appara√Ætre dans `Schema versions`.

---

## üîå √âtape 5 : Connexion au cluster

### Se connecter au seed node

```bash
docker exec -it cassandra-seed cqlsh
```

**R√©sultat :**
```
Connected to DevCluster at 127.0.0.1:9042
[cqlsh 6.1.0 | Cassandra 4.1.x | CQL spec 3.4.6 | Native protocol v5]
Use HELP for help.
cqlsh>
```

### V√©rifier la topologie depuis CQL

```sql
SELECT * FROM system.peers;
```

**R√©sultat :**
```
 peer         | data_center  | host_id                              | rack
--------------+--------------+--------------------------------------+-------
 172.20.0.3   | datacenter1  | def456...                            | rack1
 172.20.0.4   | datacenter1  | ghi789...                            | rack1
```

‚úÖ Les **2 autres n≈ìuds** sont bien reconnus.

---

## üìä √âtape 6 : Cr√©er un keyspace avec r√©plication

Maintenant, cr√©ons un keyspace qui **r√©plique les donn√©es sur les 3 n≈ìuds**.

### Cr√©er le keyspace

```sql
CREATE KEYSPACE IF NOT EXISTS demo_cluster
WITH replication = {
  'class': 'NetworkTopologyStrategy',
  'datacenter1': 3
};
```

**Explication :**

| Param√®tre | Valeur | Description |
|-----------|--------|-------------|
| `class` | `NetworkTopologyStrategy` | Strat√©gie de r√©plication multi-datacenter |
| `datacenter1` | `3` | **Replication Factor** = 3 (copie sur 3 n≈ìuds) |

**Pourquoi `NetworkTopologyStrategy` ?**
- Plus flexible que `SimpleStrategy`
- Recommand√© m√™me pour un seul datacenter
- Pr√™t pour l'ajout de datacenters futurs

### Utiliser le keyspace

```sql
USE demo_cluster;
```

### Cr√©er une table

```sql
CREATE TABLE IF NOT EXISTS users (
  user_id UUID PRIMARY KEY,
  username TEXT,
  email TEXT,
  created_at TIMESTAMP
);
```

### Ins√©rer des donn√©es

```sql
INSERT INTO users (user_id, username, email, created_at)
VALUES (uuid(), 'alice', 'alice@example.com', toTimestamp(now()));

INSERT INTO users (user_id, username, email, created_at)
VALUES (uuid(), 'bob', 'bob@example.com', toTimestamp(now()));

INSERT INTO users (user_id, username, email, created_at)
VALUES (uuid(), 'charlie', 'charlie@example.com', toTimestamp(now()));
```

### V√©rifier les donn√©es

```sql
SELECT * FROM users;
```

---

## üîÑ √âtape 7 : Tester la r√©plication

Les donn√©es sont-elles vraiment r√©pliqu√©es sur les 3 n≈ìuds ?

### V√©rifier sur le n≈ìud 2

```bash
docker exec -it cassandra-node2 cqlsh
```

```sql
USE demo_cluster;
SELECT * FROM users;
```

**R√©sultat :**
```
 user_id                              | username | email               | created_at
--------------------------------------+----------+---------------------+---------------------------
 a1b2c3d4-...                         | alice    | alice@example.com   | 2024-10-31 10:30:00+0000
 e5f6g7h8-...                         | bob      | bob@example.com     | 2024-10-31 10:30:05+0000
 i9j0k1l2-...                         | charlie  | charlie@example.com | 2024-10-31 10:30:10+0000
```

‚úÖ **Les m√™mes donn√©es** apparaissent !

### V√©rifier sur le n≈ìud 3

```bash
docker exec -it cassandra-node3 cqlsh
```

```sql
USE demo_cluster;
SELECT COUNT(*) FROM users;
```

**R√©sultat :**
```
 count
-------
     3
```

‚úÖ Les **3 enregistrements** sont pr√©sents sur tous les n≈ìuds.

---

## üõ°Ô∏è √âtape 8 : Tester la haute disponibilit√©

Que se passe-t-il si un n≈ìud tombe ?

### Arr√™ter le n≈ìud 3

```bash
docker-compose stop cassandra-node3
```

### V√©rifier l'√©tat du cluster

```bash
docker exec -it cassandra-seed nodetool status
```

**R√©sultat :**
```
--  Address      Load       Tokens  Owns (effective)  Host ID      Rack
UN  172.20.0.2   108.5 KiB  16      100.0%            abc123...    rack1
UN  172.20.0.3   104.2 KiB  16      100.0%            def456...    rack1
DN  172.20.0.4   107.8 KiB  16      100.0%            ghi789...    rack1
```

- `DN` = **Down Normal** (n≈ìud arr√™t√© mais reconnu)

### Les donn√©es sont-elles toujours accessibles ?

```bash
docker exec -it cassandra-seed cqlsh
```

```sql
USE demo_cluster;
SELECT * FROM users;
```

**R√©sultat :**
```
 user_id                              | username | email               | created_at
--------------------------------------+----------+---------------------+---------------------------
 a1b2c3d4-...                         | alice    | alice@example.com   | 2024-10-31 10:30:00+0000
 e5f6g7h8-...                         | bob      | bob@example.com     | 2024-10-31 10:30:05+0000
 i9j0k1l2-...                         | charlie  | charlie@example.com | 2024-10-31 10:30:10+0000
```

‚úÖ **Toutes les donn√©es sont accessibles !** Gr√¢ce au Replication Factor = 3.

### Red√©marrer le n≈ìud 3

```bash
docker-compose start cassandra-node3
```

Attendez quelques secondes, puis v√©rifiez :

```bash
docker exec -it cassandra-seed nodetool status
```

**R√©sultat :**
```
UN  172.20.0.2   ...
UN  172.20.0.3   ...
UN  172.20.0.4   ...
```

‚úÖ Le n≈ìud 3 est de retour (`UN`).

---

## üìê Concepts importants

### 1. Replication Factor (RF)

**D√©finition :** Nombre de copies de chaque donn√©e dans le cluster.

| RF | Description | Tol√©rance de panne |
|----|-------------|--------------------|
| 1 | Une seule copie | Aucune (perte de n≈ìud = perte de donn√©es) |
| 2 | Deux copies | Perte d'un n≈ìud tol√©r√©e |
| **3** | Trois copies | Perte de deux n≈ìuds tol√©r√©e |

**Recommandation :** RF = 3 minimum en production.

### 2. Consistency Level (CL)

**D√©finition :** Nombre de r√©plicas qui doivent r√©pondre pour une lecture/√©criture.

| CL | Description | Garantie |
|----|-------------|----------|
| `ONE` | 1 n≈ìud r√©pond | Rapide, peu fiable |
| `QUORUM` | Majorit√© r√©pond (RF/2 + 1) | √âquilibr√© (recommand√©) |
| `ALL` | Tous les n≈ìuds r√©pondent | Tr√®s fiable, lent |

**Par d√©faut :** `ONE` (pour les tests).

**Exemple avec QUORUM :**
```sql
-- Lecture avec QUORUM
CONSISTENCY QUORUM;
SELECT * FROM users;

-- √âcriture avec QUORUM
INSERT INTO users (user_id, username, email, created_at)
VALUES (uuid(), 'david', 'david@example.com', toTimestamp(now()));
```

### 3. Seed Nodes

**D√©finition :** N≈ìuds de r√©f√©rence pour rejoindre le cluster.

- Le premier n≈ìud √† d√©marrer
- Les autres n≈ìuds le contactent pour rejoindre le cluster
- **Ne pas confondre** avec "master" (Cassandra est d√©centralis√©)

**Recommandation :** Au moins 2 seeds en production.

### 4. Tokens et Partitionnement

**Token :** Hash qui d√©termine sur quel n≈ìud une donn√©e est stock√©e.

- Par d√©faut : 16 tokens par n≈ìud (num_tokens=16)
- Cassandra distribue automatiquement les donn√©es

**Exemple :**
```
Donn√©e avec cl√© primaire "alice"
‚Üí Hash = 12345678
‚Üí Token dans la plage du n≈ìud 2
‚Üí Stock√©e sur n≈ìud 2 (et r√©pliqu√©e sur n≈ìuds 1 et 3)
```

---

## üõ†Ô∏è √âtape 9 : Commandes utiles

### √âtat d√©taill√© d'un n≈ìud

```bash
docker exec -it cassandra-seed nodetool info
```

### Statistiques du cluster

```bash
docker exec -it cassandra-seed nodetool status --resolve-ip
```

### Voir les keyspaces

```bash
docker exec -it cassandra-seed cqlsh -e "DESCRIBE KEYSPACES;"
```

### Distribution des donn√©es

```bash
docker exec -it cassandra-seed nodetool getendpoints demo_cluster users <user_id>
```

Remplacez `<user_id>` par un UUID r√©el de votre table.

**R√©sultat :**
```
172.20.0.2
172.20.0.3
172.20.0.4
```

‚úÖ La donn√©e est bien pr√©sente sur les 3 n≈ìuds.

### R√©parer un n≈ìud

Si un n≈ìud a √©t√© arr√™t√© longtemps :

```bash
docker exec -it cassandra-node3 nodetool repair
```

---

## üßπ √âtape 10 : Nettoyage complet

### Arr√™ter le cluster

```bash
docker-compose stop
```

### Supprimer le cluster (conteneurs + donn√©es)

```bash
docker-compose down -v
```

### Supprimer le r√©seau

```bash
docker network rm cassandra_cluster_net
```

### V√©rification

```bash
docker ps -a | grep cassandra
docker volume ls | grep cassandra
docker network ls | grep cassandra
```

Tout doit √™tre vide.

---

## üö® Troubleshooting

### Probl√®me : Un n≈ìud reste en √©tat "Joining"

**Sympt√¥me :**
```
UJ  172.20.0.3   ...
```

**Causes possibles :**
- Le seed n'est pas compl√®tement d√©marr√©
- Probl√®me de connectivit√© r√©seau

**Solution :**
```bash
# V√©rifier les logs
docker-compose logs cassandra-node2

# Red√©marrer le n≈ìud
docker-compose restart cassandra-node2
```

### Probl√®me : "Schema disagreement"

**Sympt√¥me :**
```
Cluster Information:
    Schema versions:
        abc123: [172.20.0.2]
        def456: [172.20.0.3, 172.20.0.4]
```

**Solution :**
```bash
# Sur chaque n≈ìud
docker exec -it cassandra-seed nodetool describecluster
docker exec -it cassandra-node2 nodetool describecluster
docker exec -it cassandra-node3 nodetool describecluster

# Attendre quelques minutes (propagation automatique)
# Ou forcer la synchronisation
docker exec -it cassandra-seed nodetool repair
```

### Probl√®me : Ressources insuffisantes

**Sympt√¥me :** Les conteneurs red√©marrent en boucle.

**Solution :**
- Augmenter la RAM Docker (dans les param√®tres Docker Desktop)
- Ou r√©duire `MAX_HEAP_SIZE` √† `256M`

### Probl√®me : Port 9042 d√©j√† utilis√©

**Solution :**
Changez le port dans `docker-compose.yml` :
```yaml
ports:
  - "9043:9042"  # Port externe diff√©rent
```

---

## üí° Conseils pour d√©butants

### 1. Toujours attendre le healthcheck

Ne vous connectez pas avant que tous les n≈ìuds soient `healthy`.

### 2. Utiliser `nodetool status` en premier

C'est votre meilleur ami pour diagnostiquer l'√©tat du cluster.

### 3. Commencer par RF=3 et CL=QUORUM

Configuration √©quilibr√©e entre performance et fiabilit√©.

### 4. Monitoring des logs

Gardez un terminal avec `docker-compose logs -f` ouvert pendant le d√©marrage.

### 5. Documentez vos keyspaces

Cr√©ez un fichier `KEYSPACES.md` :
```markdown
# Keyspaces

## demo_cluster
- RF: 3
- Tables: users
- Usage: D√©mo du tutoriel
```

---

## üìö Prochaines √©tapes

Maintenant que vous ma√Ætrisez les clusters, explorez :

- **[7.4 Gestion des keyspaces](04-gestion-keyspaces.md)** : Strat√©gies de r√©plication avanc√©es
- **[Annexe G - Comparaison des BDD](/annexes/G-comparaison-bdd.md)** : Quand utiliser Cassandra
- **[Cas pratique - Environnement de dev complet](/cas-pratiques/04-env-dev-complet.md)** : Cassandra avec applications

---

## ‚ùì Questions fr√©quentes (FAQ)

**Q : Combien de n≈ìuds seeds recommandez-vous ?**
R : 2-3 seeds suffisent, m√™me pour de gros clusters. Pas besoin que tous les n≈ìuds soient seeds.

**Q : Puis-je ajouter un 4√®me n≈ìud au cluster ?**
R : Oui ! Copiez la config de `cassandra-node3`, changez l'IP (`172.20.0.5`) et lancez `docker-compose up -d`.

**Q : Quelle est la diff√©rence entre RF et nombre de n≈ìuds ?**
R : RF = nombre de copies. Vous pouvez avoir RF=3 sur un cluster de 10 n≈ìuds.

**Q : Les performances sont-elles multipli√©es par 3 ?**
R : Pas exactement. Les √©critures sont plus rapides (distribution), les lectures d√©pendent du CL.

**Q : Cassandra est-il mieux que MongoDB pour un cluster ?**
R : Cassandra excelle pour les √©critures massives et la haute disponibilit√©. MongoDB est plus flexible pour les requ√™tes complexes.

**Q : Comment migrer d'un n≈ìud unique vers un cluster ?**
R : Exportez les donn√©es (cqlsh COPY), cr√©ez le cluster, importez les donn√©es.

---

## üîó Ressources compl√©mentaires

- [Documentation Cassandra - Architecture](https://cassandra.apache.org/doc/latest/cassandra/architecture/)
- [DataStax - Understanding Replication](https://docs.datastax.com/en/cassandra-oss/3.x/cassandra/architecture/archDataDistributeReplication.html)
- [Cassandra Best Practices](https://cassandra.apache.org/doc/latest/cassandra/operating/index.html)

---

üîù Retour au [Sommaire](/SOMMAIRE.md)

---

*Derni√®re mise √† jour : Octobre 2025*
